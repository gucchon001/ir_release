ir_news_release
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .pytest_cache
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ CACHEDIR.TAG
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ v
â”‚       â””â”€â”€ cache
â”‚           â”œâ”€â”€ lastfailed
â”‚           â”œâ”€â”€ nodeids
â”‚           â””â”€â”€ stepwise
â”œâ”€â”€ .req_hash
â”œâ”€â”€ README.md
â”œâ”€â”€ config
â”‚   â”œâ”€â”€ boxwood-dynamo-384411-6dec80faabfc.json
â”‚   â”œâ”€â”€ prompt_financial_report.json
â”‚   â”œâ”€â”€ secrets.env
â”‚   â””â”€â”€ settings.ini
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ detail_spec.txt
â”‚   â”œâ”€â”€ generate_detailed_spec.txt
â”‚   â”œâ”€â”€ merge.txt
â”‚   â””â”€â”€ requirements_spec.txt
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run.bat
â”œâ”€â”€ spec_tools_run.bat
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ edinet
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”‚   â””â”€â”€ operations.py
â”‚   â”‚   â”œâ”€â”€ pdfSummary
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ extractor.py
â”‚   â”‚   â”‚   â”œâ”€â”€ pdf_main.py
â”‚   â”‚   â”‚   â”œâ”€â”€ process_drive_file.py
â”‚   â”‚   â”‚   â”œâ”€â”€ summarizer.py
â”‚   â”‚   â”‚   â””â”€â”€ tokenizer.py
â”‚   â”‚   â”œâ”€â”€ setup.py
â”‚   â”‚   â”œâ”€â”€ slack
â”‚   â”‚   â”‚   â””â”€â”€ slack_notify.py
â”‚   â”‚   â””â”€â”€ spreadsheet_to_edinet.py
â”‚   â””â”€â”€ utils
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ date_utils.py
â”‚       â”œâ”€â”€ drive_handler.py
â”‚       â”œâ”€â”€ environment.py
â”‚       â”œâ”€â”€ logging_config.py
â”‚       â””â”€â”€ spreadsheet.py
â””â”€â”€ tests
    â”œâ”€â”€ README.md
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_drive_file.py
    â”œâ”€â”€ test_log.py
    â”œâ”€â”€ test_slack_notify.py
    â”œâ”€â”€ test_slack_notify_with_file.py
    â”œâ”€â”€ test_slack_notify_with_markdown.py
    â”œâ”€â”€ test_spreadsheet.py
    â””â”€â”€ test_template.py

# Merged Python Files


================================================================================
File: src\__init__.py
================================================================================

 


================================================================================
File: src\main.py
================================================================================

#main.py
from typing import Callable, Optional, Any
from datetime import datetime, timedelta

from modules.edinet.operations import EDINETOperations
from modules.edinet.config import EDINETConfig
from modules.spreadsheet_to_edinet import process_spreadsheet_data
from utils.spreadsheet import SpreadsheetService
from utils.environment import EnvironmentUtils as env
from utils.date_utils import parse_date_string
from utils.logging_config import get_logger

# åå‰ä»˜ããƒ­ã‚¬ãƒ¼ã‚’å–å¾—
logger = get_logger(__name__)

def initialize_debug_tools() -> None:
    """
    ãƒ‡ãƒãƒƒã‚°ãƒ„ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–
    """
    try:
        use_icecream = env.get_config_value(env.get_environment(), "USE_ICECREAM", default=False)
        # ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–æ™‚ã«IceCreamã®è¨­å®šã‚’åæ˜ 
        get_logger(__name__, use_icecream=use_icecream)
    except Exception as e:
        logger.error(f"Failed to initialize debug tools: {e}")
        raise

def run_process(process_func: Callable, config: Optional[Any] = None) -> None:
    """æ±ç”¨ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œé–¢æ•°"""
    try:
        logger.info(f"Starting process: {process_func.__name__}")
        process_func(config)
        logger.info(f"Process {process_func.__name__} completed successfully.")
    except Exception as e:
        logger.error(f"Error in {process_func.__name__}: {e}", exc_info=True)
        raise RuntimeError(f"Process {process_func.__name__} failed.") from e

def edinet_process(config: EDINETConfig) -> None:
    """
    EDINET API ã‚’ä½¿ç”¨ã—ã¦æŒ‡å®šã•ã‚ŒãŸæœŸé–“å†…ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
    """
    edinet = EDINETOperations(
        base_url=config.base_url,
        api_key=config.api_key,
        parent_folder_id=config.parent_folder_id,
        service_account_file=config.service_account_file,
    )

    start_date_str = env.get_config_value("DATE_RANGE", "start_date")
    end_date_str = env.get_config_value("DATE_RANGE", "end_date")

    if not start_date_str or not end_date_str:
        raise ValueError("DATE_RANGE section or required keys are missing in the settings.ini file.")

    # å‹•çš„ãªæ—¥ä»˜è§£æ
    start_date = parse_date_string(start_date_str)
    end_date = parse_date_string(end_date_str)
    
    logger.debug(f"Fetching documents from {start_date} to {end_date}")

    spreadsheet_service = SpreadsheetService()
    spreadsheet_id = spreadsheet_service.get_spreadsheet_id("SPREADSHEET", "ss_id_list")
    list_data = spreadsheet_service.get_sheet_data(spreadsheet_id, "list")

    if not list_data or len(list_data) < 2:
        logger.error("Spreadsheet data is empty or invalid format.")
        raise ValueError("Spreadsheet data is empty or invalid format.")

    headers = list_data[0]
    data_rows = list_data[1:]
    edinet_code_index = headers.index("EDINET_code")
    edinet_codes_from_sheet = [row[edinet_code_index] for row in data_rows]

    logger.info(f"Edinet codes retrieved from spreadsheet.")

    documents = edinet.get_documents_for_date_range(
        start_date=start_date,
        end_date=end_date,
        edinet_codes_from_sheet=edinet_codes_from_sheet
    )

    logger.info(f"Total documents retrieved: {len(documents)}")
    for document in documents:
        logger.debug(f"Retrieved Document - ID: {document.get('docID')}, Description: {document.get('docDescription')}")

def main() -> None:
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    try:
        # ç’°å¢ƒå¤‰æ•°ã®ãƒ­ãƒ¼ãƒ‰
        env.load_env()

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—
        config_path = env.get_config_file()
        logger.info(f"Config file located at: {config_path}")

        # EDINETã®è¨­å®šã‚’åˆæœŸåŒ–
        edinet_config = EDINETConfig()
        edinet_config.config_path = config_path

        logger.info(f"Current environment: {env.get_environment()}")

        # ãƒ‡ãƒãƒƒã‚°ãƒ„ãƒ¼ãƒ«ã®åˆæœŸåŒ–
        initialize_debug_tools()

        # å„ãƒ—ãƒ­ã‚»ã‚¹ã®å®Ÿè¡Œ
        run_process(edinet_process, edinet_config)
        run_process(process_spreadsheet_data, edinet_config)

    except Exception as e:
        logger.error(f"Fatal error in main execution: {e}", exc_info=True)

if __name__ == "__main__":
    main()


================================================================================
File: src\modules\__init__.py
================================================================================

# src/modules/__init__.py
from . import pdfSummary
from . import edinet

================================================================================
File: src\modules\edinet\__init__.py
================================================================================

 


================================================================================
File: src\modules\edinet\config.py
================================================================================

#config.py
from pathlib import Path
from typing import Optional
from utils.environment import EnvironmentUtils as env
from utils.logging_config import get_logger

# åå‰ä»˜ããƒ­ã‚¬ãƒ¼ã‚’å–å¾—
logger = get_logger(__name__)

class EDINETConfig:
    REQUIRED_KEYS = ['base_url', 'api_key', 'parent_folder_id']

    def __init__(self, environment: Optional[str] = None):
        """
        EDINETConfigã®åˆæœŸåŒ–

        Args:
            environment (Optional[str]): ç’°å¢ƒåï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç¾åœ¨ã®ç’°å¢ƒã‚’è‡ªå‹•å–å¾—ï¼‰
        """
        self.environment = environment or env.get_environment()
        self.settings = {}

        logger.info(f"Initializing EDINETConfig for environment: {self.environment}")

        # .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        self._load_env()

        # è¨­å®šã®èª­ã¿è¾¼ã¿ã¨æ¤œè¨¼
        self._load_settings()
        self._validate_settings()

    def _load_env(self):
        """
        ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
        """
        try:
            env.load_env()
            logger.info("Environment variables loaded successfully.")
        except FileNotFoundError as e:
            logger.error(f"Environment file not found: {e}")
            raise

    def _load_settings(self):
        """
        EnvironmentUtilsã‚’åˆ©ç”¨ã—ã¦è¨­å®šã‚’èª­ã¿è¾¼ã‚€
        """
        try:
            # ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’ãƒ­ãƒ¼ãƒ‰
            self.settings['api_key'] = env.get_env_var("EDINET_API_KEY", default=env.get_config_value("EDINET", "api_key"))
            if not self.settings['api_key']:
                logger.warning("API key is missing. Please set 'EDINET_API_KEY' or define it in settings.ini.")

            self.settings['base_url'] = env.get_config_value('EDINET', 'base_url', default="https://disclosure.edinet-fsa.go.jp/api/v1")
            self.settings['parent_folder_id'] = env.get_config_value('DRIVE', 'parent_folder_id', default="")

            # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’secrets.envã¾ãŸã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—
            service_account_file = env.get_env_var("SERVICE_ACCOUNT_FILE", default=env.get_config_value("GOOGLE", "service_account_file"))
            if not service_account_file:
                raise ValueError("Service account file is missing. Please set 'SERVICE_ACCOUNT_FILE' in secrets.env or settings.ini.")

            self.settings['service_account_file'] = self._resolve_path(service_account_file)
            self.settings['download_dir'] = env.get_config_value('EDINET', 'download_dir', default="data/edinet")

            logger.info("Configuration settings loaded successfully.")
        except Exception as e:
            logger.error(f"Failed to load settings: {e}")
            raise

    def _validate_settings(self):
        """
        è¨­å®šå€¤ã®æ¤œè¨¼

        Raises:
            ValueError: å¿…é ˆã‚­ãƒ¼ãŒæ¬ è½ã—ã¦ã„ã‚‹å ´åˆ
        """
        logger.info("Validating configuration settings...")
        missing_keys = [key for key in self.REQUIRED_KEYS if not self.settings.get(key)]
        if not self.settings.get('service_account_file'):
            missing_keys.append('service_account_file')

        if missing_keys:
            logger.error(f"Missing required configuration keys: {', '.join(missing_keys)}")
            raise ValueError(f"Missing required configuration keys: {', '.join(missing_keys)}")
        logger.info("All required settings are valid.")

    def _resolve_path(self, path: str) -> Path:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã«åŸºã¥ã„ã¦è§£æ±ºã—ã¾ã™ã€‚

        Args:
            path (str): ç›¸å¯¾ãƒ‘ã‚¹ã¾ãŸã¯çµ¶å¯¾ãƒ‘ã‚¹

        Returns:
            Path: è§£æ±ºã•ã‚ŒãŸçµ¶å¯¾ãƒ‘ã‚¹
        """
        resolved_path = Path(path)
        if not resolved_path.is_absolute():
            resolved_path = env.get_project_root() / resolved_path

        if not resolved_path.exists():
            logger.error(f"Resolved path does not exist: {resolved_path}")
            raise FileNotFoundError(f"Resolved path does not exist: {resolved_path}")

        return resolved_path

    @property
    def base_url(self) -> str:
        """
        EDINET APIã®ãƒ™ãƒ¼ã‚¹URLã‚’å–å¾—
        """
        return self.settings.get('base_url')

    @property
    def api_key(self) -> str:
        """
        EDINET APIã‚­ãƒ¼ã‚’å–å¾—
        """
        return self.settings.get('api_key')

    @property
    def parent_folder_id(self) -> str:
        """
        Google Driveã®è¦ªãƒ•ã‚©ãƒ«ãƒ€IDã‚’å–å¾—
        """
        return self.settings.get('parent_folder_id')

    @property
    def service_account_file(self) -> Path:
        """
        ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—
        """
        return self.settings.get('service_account_file')

    def get_download_dir(self) -> Path:
        """
        ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’å–å¾—

        Returns:
            Path: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
        """
        download_dir = Path(self.settings.get('download_dir'))
        if not download_dir.is_absolute():
            download_dir = env.get_project_root() / download_dir
        download_dir.mkdir(parents=True, exist_ok=True)
        return download_dir


================================================================================
File: src\modules\edinet\operations.py
================================================================================

#operations.py
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import requests
from google.oauth2 import service_account
from googleapiclient.discovery import build
from utils.environment import EnvironmentUtils as env
from utils.logging_config import get_logger
import os
from concurrent.futures import ThreadPoolExecutor, as_completed

# åå‰ä»˜ããƒ­ã‚¬ãƒ¼ã‚’å–å¾—
logger = get_logger(__name__)

class EDINETOperations:
    """EDINET APIæ“ä½œã‚¯ãƒ©ã‚¹"""

    TARGET_DOC_TYPES: Dict[str, str] = {
        '120': 'æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸',
        '140': 'å››åŠæœŸå ±å‘Šæ›¸',
        '160': 'åŠæœŸå ±å‘Šæ›¸'
    }

    def __init__(self, base_url: Optional[str] = None, api_key: Optional[str] = None, 
                 parent_folder_id: Optional[str] = None, service_account_file: Optional[str] = None, 
                 max_workers: int = 10):
        """
        EDINETOperations ã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–
        """
        logger.info("EDINET Operations ã‚’åˆæœŸåŒ–ä¸­...")

        # ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
        env.load_env()

        # å¿…è¦ãªè¨­å®šã‚’EnvironmentUtilsã‹ã‚‰å–å¾—
        try:
            self.base_url = base_url or env.get_config_value("EDINET", "base_url")
            self.api_key = api_key or os.getenv("EDINET_API_KEY")  # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
            self.parent_folder_id = parent_folder_id or env.get_config_value("DRIVE", "parent_folder_id")
            self.service_account_file = service_account_file or env.get_service_account_file()

            # è¨­å®šå€¤ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã«ã‚¨ãƒ©ãƒ¼ã‚’ã‚¹ãƒ­ãƒ¼
            missing_config = []
            if not self.base_url:
                missing_config.append("base_url")
            if not self.api_key:
                missing_config.append("api_key")
            if not self.service_account_file:
                missing_config.append("service_account_file")

            if missing_config:
                raise ValueError(f"å¿…è¦ãªè¨­å®šå€¤ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing_config)}")
            
            logger.debug("è¨­å®šå€¤ã‚’æ­£å¸¸ã«ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")

        except Exception as e:
            logger.error(f"EDINETOperations ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            raise

        # Google Drive APIã‚’åˆæœŸåŒ–
        self.drive_service = None
        self.initialize_drive_service()

        # ThreadPoolExecutorã®æœ€å¤§ã‚¹ãƒ¬ãƒƒãƒ‰æ•°
        self.max_workers = max_workers

    def initialize_drive_service(self):
        """Google Drive APIã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–"""
        try:
            credentials = service_account.Credentials.from_service_account_file(
                str(self.service_account_file),
                scopes=['https://www.googleapis.com/auth/drive.file']
            )
            self.drive_service = build('drive', 'v3', credentials=credentials)
            logger.info("Google Drive ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ­£å¸¸ã«åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            logger.error(f"Drive ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            self.drive_service = None

    def get_documents_for_date_range(self, start_date: datetime, end_date: datetime, edinet_codes_from_sheet: List[str]) -> List[Dict]:
        """
        æŒ‡å®šæœŸé–“ã®EDINETæ–‡æ›¸ã‚’å–å¾—

        Args:
            start_date (datetime): é–‹å§‹æ—¥
            end_date (datetime): çµ‚äº†æ—¥
            edinet_codes_from_sheet (List[str]): ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰å–å¾—ã—ãŸEDINETã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ

        Returns:
            List[Dict]: æ–‡æ›¸æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        documents = []
        total_days = (end_date - start_date).days + 1
        dates = [(start_date + timedelta(days=day_offset)).strftime('%Y-%m-%d') for day_offset in range(total_days)]

        logger.info(f"{total_days} æ—¥åˆ†ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¸¦åˆ—ã§å–å¾—é–‹å§‹ã—ã¾ã™ã€‚")

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_date = {executor.submit(self.fetch_documents_for_date, date, edinet_codes_from_sheet): date for date in dates}
            for future in as_completed(future_to_date):
                date = future_to_date[future]
                try:
                    daily_documents = future.result()
                    documents.extend(daily_documents)
                    logger.debug(f"{date} ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ {len(daily_documents)} ä»¶å–å¾—ã—ã¾ã—ãŸã€‚")
                except Exception as e:
                    logger.error(f"{date} ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–å¾—ä¸­ã«ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

        logger.info(f"æŒ‡å®šæœŸé–“å†…ã«å–å¾—ã—ãŸç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(documents)}")
        return documents

    def fetch_documents_for_date(self, target_date: str, edinet_codes_from_sheet: List[str]) -> List[Dict]:
        """
        æŒ‡å®šæ—¥ã®EDINETæ–‡æ›¸ã‚’å–å¾—

        Args:
            target_date (str): å¯¾è±¡æ—¥ (YYYY-MM-DD)
            edinet_codes_from_sheet (List[str]): ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰å–å¾—ã—ãŸEDINETã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ

        Returns:
            List[Dict]: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸæ–‡æ›¸æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        filtered_results = []
        logger.debug(f"{target_date} ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ä¸­...")

        try:
            url = f"{self.base_url}/documents.json"
            params = {
                "date": target_date,
                "type": "2",
                "Subscription-Key": self.api_key
            }
            response = requests.get(url, params=params, timeout=10)

            if response.status_code != 200:
                logger.warning(f"{target_date} ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæˆåŠŸã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {response.text}")
                return []

            data = response.json()
            results = data.get('results', [])

            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¯¾è±¡ã®EDINETã‚³ãƒ¼ãƒ‰ã®ã¿å–å¾—
            filtered_results = [
                doc for doc in results
                if (doc.get('edinetCode') in edinet_codes_from_sheet and
                    doc.get('docTypeCode') in self.TARGET_DOC_TYPES and
                    doc.get('pdfFlag') == '1')
            ]

            logger.info(f"{target_date} ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœæ•°: {len(filtered_results)}")
            return filtered_results

        except requests.exceptions.RequestException as e:
            logger.error(f"{target_date} ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return []
        except Exception as e:
            logger.error(f"{target_date} ã®å‡¦ç†ä¸­ã«äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return []

    def fetch_document_data(self, doc_id: str, doc_type_code: str) -> Optional[bytes]:
        """
        EDINET APIã‹ã‚‰PDFãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

        Args:
            doc_id (str): ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID
            doc_type_code (str): ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã‚³ãƒ¼ãƒ‰

        Returns:
            Optional[bytes]: PDFãƒ‡ãƒ¼ã‚¿ã€ã¾ãŸã¯None
        """
        url = f"{self.base_url}/documents/{doc_id}"
        params = {
            "type": "2",  # PDFãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’æŒ‡å®š
            "Subscription-Key": self.api_key,
        }

        logger.debug(f"doc_id {doc_id} ã®PDFãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­...")

        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()

            # PDFãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒã‚§ãƒƒã‚¯
            if not response.content.startswith(b'%PDF-'):
                logger.error(f"doc_id {doc_id} ã®PDFãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒç„¡åŠ¹ã§ã™ã€‚")
                return None

            logger.debug(f"doc_id {doc_id} ã®PDFãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ­£å¸¸ã«å–å¾—ã—ã¾ã—ãŸã€‚ã‚µã‚¤ã‚º: {len(response.content)} ãƒã‚¤ãƒˆ")
            return response.content
        except requests.exceptions.RequestException as e:
            logger.error(f"doc_id {doc_id} ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None


================================================================================
File: src\modules\pdfSummary\__init__.py
================================================================================

 
# src/modules/pdfSummary/__init__.py
from . import pdf_main
from . import extractor
from . import tokenizer
from . import summarizer

================================================================================
File: src\modules\pdfSummary\extractor.py
================================================================================

import pymupdf
from utils.logging_config import get_logger  # ä¿®æ­£: çµ¶å¯¾ãƒ‘ã‚¹ã‚’ä½¿ç”¨

logger = get_logger(__name__)

def extract_text_from_pdf(pdf_path):
    """
    PyMuPDF ã‚’ä½¿ç”¨ã—ã¦PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¾ã™ã€‚

    Args:
        pdf_path (str): PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€‚

    Returns:
        str: æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã€‚
    """
    logger.info(f"PDF ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º: {pdf_path}")
    text = ""
    try:
        doc = pymupdf.open(pdf_path)
        for page_num, page in enumerate(doc, start=1):
            page_text = page.get_text()
            if page_text:
                text += page_text + "\n\n"
            logger.debug(f"ãƒšãƒ¼ã‚¸ {page_num}: ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå®Œäº†")
    except Exception as e:
        logger.error(f"PyMuPDF ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise
    logger.info(f"æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®åˆè¨ˆæ–‡å­—æ•°: {len(text)}")
    return text


================================================================================
File: src\modules\pdfSummary\pdf_main.py
================================================================================

# src/modules/pdfSummary/pdf_main.py

import openai  # OpenAI SDK ã®æ­£ã—ã„ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–¹æ³•
from pathlib import Path
import json

from utils.environment import EnvironmentUtils as env
from utils.drive_handler import DriveHandler
from .extractor import extract_text_from_pdf
from .tokenizer import Tokenizer
from .summarizer import Summarizer

from utils.logging_config import get_logger

logger = get_logger(__name__)

def load_prompt(file_path: str) -> list:
    """
    ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹

    Args:
        file_path (str): ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        list: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            prompt_data = json.load(file)
            return prompt_data["messages"]
    except Exception as e:
        logger.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        raise

def process_pdf(pdf_path: str, folder_id: str, drive_handler: DriveHandler = None) -> list:
    """
    PDF ã‚’å‡¦ç†ã—ã¦è¦ç´„ã‚’ä½œæˆã—ã€Google Drive ã«ä¿å­˜ã—ã¾ã™ã€‚

    Args:
        pdf_path (str): PDF ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€‚
        folder_id (str): è¦ç´„ã‚’ä¿å­˜ã™ã‚‹ Google Drive ãƒ•ã‚©ãƒ«ãƒ€ã® IDã€‚
        drive_handler (DriveHandler, optional): æ—¢å­˜ã®DriveHandlerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚

    Returns:
        list: Google Drive ã«ä¿å­˜ã•ã‚ŒãŸè¦ç´„ãƒ•ã‚¡ã‚¤ãƒ«ã® ID ã®ãƒªã‚¹ãƒˆã€‚
    """
    logger.info(f"PDF å‡¦ç†ã‚’é–‹å§‹: {pdf_path}")

    # ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
    try:
        env.load_env()
        logger.info("ç’°å¢ƒå¤‰æ•°ã‚’æ­£å¸¸ã«ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        logger.error(f"ç’°å¢ƒå¤‰æ•°ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        raise

    # å¿…è¦ãªæƒ…å ±ã‚’ãƒ­ãƒ¼ãƒ‰
    api_key = env.get_openai_api_key()
    model = env.get_openai_model()
    max_chunk_tokens = 2000  # åˆ†å‰²ã‚µã‚¤ã‚º
    max_summary_tokens = 2000  # è¦ç´„ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰
    prompt_path = env.get_config_value("OPENAI", "prompt_financial_report", default="config/prompt_financial_report.json")
    prompt_file_path = env.resolve_path(prompt_path)
    try:
        prompt_messages = load_prompt(prompt_file_path)
        logger.info("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ­£å¸¸ã«ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        logger.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise

    # å¿…è¦ãªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆ
    openai.api_key = api_key  # OpenAI API ã‚­ãƒ¼ã‚’è¨­å®š
    tokenizer = Tokenizer(model, max_chunk_tokens)
    summarizer = Summarizer(openai, model, max_summary_tokens, prompt_messages)

    # DriveHandlerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆï¼ˆæ—¢å­˜ã®DriveHandlerãŒã‚ã‚Œã°ä½¿ç”¨ï¼‰
    if drive_handler is None:
        service_account_file = env.get_service_account_file()
        drive_handler = DriveHandler(str(service_account_file))

    # PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
    try:
        text = extract_text_from_pdf(pdf_path)
    except Exception as e:
        logger.error(f"PDF ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        raise

    # ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²ã—è¦ç´„
    try:
        chunks = tokenizer.split_text_into_chunks(text)
        summary = summarizer.summarize_text(chunks)
    except Exception as e:
        logger.error(f"è¦ç´„å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        raise

    # è¦ç´„ã‚’Google Driveã«ä¿å­˜
    try:
        file_ids = []
        if len(summary) > 10000:
            # è¦ç´„ãŒé•·ã™ãã‚‹å ´åˆã«åˆ†å‰²ä¿å­˜
            parts = [summary[i:i+10000] for i in range(0, len(summary), 10000)]
            for idx, part in enumerate(parts):
                part_file_name = f"{Path(pdf_path).stem}_summary_part_{idx+1}.md"
                file_id = drive_handler.save_summary_to_drive(folder_id, part, part_file_name)
                file_ids.append(file_id)
                logger.info(f"åˆ†å‰²è¦ç´„ã‚’Google Drive ã«ä¿å­˜ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ« ID: {file_id}")
        else:
            # é€šå¸¸ä¿å­˜
            file_name = Path(pdf_path).stem + "_summary.md"
            file_id = drive_handler.save_summary_to_drive(folder_id, summary, file_name)
            file_ids.append(file_id)
            logger.info(f"è¦ç´„ã‚’Google Drive ã«ä¿å­˜ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ« ID: {file_id}")
        return file_ids  # è¦ç´„ãƒ•ã‚¡ã‚¤ãƒ«ã®IDãƒªã‚¹ãƒˆã‚’è¿”ã™
    except Exception as e:
        logger.error(f"Google Drive ã«ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        raise

def test_process_drive_file(file_id: str, drive_folder_id: str):
    """
    Google Driveã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹ãƒ†ã‚¹ãƒˆé–¢æ•°
    
    Args:
        file_id (str): å‡¦ç†å¯¾è±¡ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã®Google Drive ID
        drive_folder_id (str): ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã®Google Drive ID
    """
    try:
        # DriveHandlerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        service_account_file = env.get_service_account_file()
        drive_handler = DriveHandler(str(service_account_file))
        
        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦å‡¦ç†
        local_pdf_path = drive_handler.download_pdf_from_drive(file_id)
        if local_pdf_path:
            # PDFã®å‡¦ç† - DriveHandler ã‚’æ¸¡ã™
            result = process_pdf(local_pdf_path, drive_folder_id, drive_handler)
            
            if result:
                print(f"å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚çµæœã®ãƒ•ã‚¡ã‚¤ãƒ«ID: {result}")
            else:
                print("PDFã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
        else:
            print("PDFã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        raise


================================================================================
File: src\modules\pdfSummary\process_drive_file.py
================================================================================

# src/modules/pdfSummary/process_drive_file.py

from .pdf_main import process_pdf
from utils.environment import EnvironmentUtils as env
from utils.drive_handler import DriveHandler
from utils.logging_config import get_logger

logger = get_logger(__name__)

def process_drive_file(file_id: str, drive_folder_id: str) -> list:
    """
    Google Driveã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦è¦ç´„ã‚’ç”Ÿæˆã—ã€ãƒ•ã‚¡ã‚¤ãƒ«IDã®ãƒªã‚¹ãƒˆã‚’è¿”ã™

    Args:
        file_id (str): å‡¦ç†å¯¾è±¡ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã®Google Drive ID
        drive_folder_id (str): ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã®Google Drive ID

    Returns:
        list: è¦ç´„ãƒ•ã‚¡ã‚¤ãƒ«ã®Google Driveãƒ•ã‚¡ã‚¤ãƒ«IDã®ãƒªã‚¹ãƒˆ
    """
    try:
        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—
        service_account_file = env.get_service_account_file()
        drive_handler = DriveHandler(str(service_account_file))

        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦å‡¦ç†
        local_pdf_path = drive_handler.download_pdf_from_drive(file_id)
        if local_pdf_path:
            # PDFã®å‡¦ç†
            result = process_pdf(local_pdf_path, drive_folder_id, drive_handler)
            if result:
                logger.info(f"å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚çµæœã®ãƒ•ã‚¡ã‚¤ãƒ«ID: {result}")
                return result
            else:
                logger.error("PDFã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return []
        else:
            logger.error("PDFã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return []
    except Exception as e:
        logger.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return []


================================================================================
File: src\modules\pdfSummary\summarizer.py
================================================================================

import tiktoken
from concurrent.futures import ThreadPoolExecutor
from utils.logging_config import get_logger

logger = get_logger(__name__)

class Summarizer:
    def __init__(self, client, model, max_summary_tokens, prompt_messages):
        self.client = client
        self.model = model
        self.max_summary_tokens = max_summary_tokens
        self.prompt_messages = prompt_messages
        self.encoding = tiktoken.encoding_for_model(model)  # tiktoken ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å–å¾—

    def summarize_chunk(self, chunk):
        """
        å˜ä¸€ã®ãƒãƒ£ãƒ³ã‚¯ã‚’è¦ç´„ã—ã¾ã™ã€‚
        """
        logger.info("ãƒãƒ£ãƒ³ã‚¯ã‚’è¦ç´„ã—ã¾ã™ã€‚")
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    *self.prompt_messages,  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é©ç”¨
                    {"role": "user", "content": chunk}
                ],
                max_tokens=self.max_summary_tokens,
                temperature=0.7
            )
            summary = response.choices[0].message.content.strip()
            logger.debug(f"è¦ç´„çµæœ: {summary[:100]}...")
            return summary
        except Exception as e:
            logger.error(f"ãƒãƒ£ãƒ³ã‚¯ã®è¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            raise

    def summarize_text(self, chunks):
        """
        è¤‡æ•°ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ã¾ã¨ã‚ã¦è¦ç´„ã€‚
        """
        logger.info("è¤‡æ•°ãƒãƒ£ãƒ³ã‚¯ã‚’ã¾ã¨ã‚ã¦è¦ç´„ã—ã¾ã™ã€‚")
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    *self.prompt_messages,
                    {"role": "user", "content": "\n\n".join(chunks)}
                ],
                max_tokens=self.max_summary_tokens,
                temperature=0.7
            )
            summary = response.choices[0].message.content.strip()
            logger.info("è¦ç´„å®Œäº†ã€‚")
            return summary
        except Exception as e:
            logger.error(f"è¦ç´„å…¨ä½“ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            raise

    def _summarize_recursive(self, summaries):
        """
        éƒ¨åˆ†è¦ç´„ãŒé•·ã™ãã‚‹å ´åˆã€ã•ã‚‰ã«åˆ†å‰²ã—ã¦å†è¦ç´„ã—ã¾ã™ã€‚
        """
        combined_summary = " ".join(summaries)
        token_count = len(self.encoding.encode(combined_summary))  # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—

        if token_count <= self.max_summary_tokens:
            return self.summarize_chunk(combined_summary)  # ãƒˆãƒ¼ã‚¯ãƒ³æ•°å†…ãªã‚‰è¦ç´„

        logger.info("å†è¦ç´„ã®ãŸã‚ã€è¦ç´„ã‚’ã•ã‚‰ã«åˆ†å‰²ã—ã¾ã™ã€‚")
        midpoint = len(summaries) // 2
        left_summary = self._summarize_recursive(summaries[:midpoint])
        right_summary = self._summarize_recursive(summaries[midpoint:])

        return self.summarize_chunk(f"{left_summary} {right_summary}")


================================================================================
File: src\modules\pdfSummary\tokenizer.py
================================================================================

from sentence_transformers import SentenceTransformer, util
import tiktoken
from utils.logging_config import get_logger

logger = get_logger(__name__)

class Tokenizer:
    def __init__(self, model, max_chunk_tokens):
        self.encoding = tiktoken.encoding_for_model(model)
        self.max_chunk_tokens = max_chunk_tokens
        self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')  # ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«

    def count_tokens(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆå†…ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¾ã™ã€‚"""
        token_count = len(self.encoding.encode(text))
        logger.debug(f"ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {token_count}")
        return token_count

    def split_text_into_chunks(self, text):
        """æ„å‘³çš„ã«è¿‘ã„ã¾ã¨ã¾ã‚Šã§ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²ã—ã¾ã™ã€‚"""
        logger.info("ãƒ†ã‚­ã‚¹ãƒˆã‚’æ„å‘³çš„ã«åˆ†å‰²ã—ã¾ã™ã€‚")

        # ãƒ†ã‚­ã‚¹ãƒˆã‚’æ–‡å˜ä½ã«åˆ†å‰²
        sentences = [sentence.strip() for sentence in text.split(".") if sentence.strip()]
        
        # å„æ–‡ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’å–å¾—
        embeddings = self.sentence_model.encode(sentences, convert_to_tensor=True)

        # æ„å‘³çš„ã«è¿‘ã„æ–‡ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã‚‹
        clusters = []
        current_cluster = []
        current_cluster_length = 0

        for i, sentence in enumerate(sentences):
            sentence_tokens = self.count_tokens(sentence)

            if current_cluster_length + sentence_tokens > self.max_chunk_tokens:
                clusters.append(" ".join(current_cluster))
                current_cluster = []
                current_cluster_length = 0

            current_cluster.append(sentence)
            current_cluster_length += sentence_tokens

        if current_cluster:
            clusters.append(" ".join(current_cluster))

        logger.info(f"åˆ†å‰²ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯æ•°: {len(clusters)}")
        return clusters


================================================================================
File: src\modules\setup.py
================================================================================

# setup.py
from setuptools import setup, find_packages

setup(
    name="ir_news_release",
    version="0.1",
    packages=find_packages(),
    package_dir={"": "src"}
)

================================================================================
File: src\modules\slack\slack_notify.py
================================================================================

# slack_notifier.py
from pathlib import Path
from slack_sdk import WebClient
from slack_sdk.errors import SlackApiError
from utils.logging_config import get_logger
import os
import re
from typing import List, Dict, Optional
from dotenv import load_dotenv

logger = get_logger(__name__)

class MarkdownSlackFormatter:
    """
    Markdownãƒ†ã‚­ã‚¹ãƒˆã‚’ Slack ã® Block Kit å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    ä¼šç¤¾ã®æ±ºç®—æƒ…å ±ã‚’æ§‹é€ åŒ–ã•ã‚ŒãŸå½¢å¼ã§è¡¨ç¤ºã—ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªè¦ç´ ã‚’æä¾›ã—ã¾ã™ã€‚
    """
    def format_content(self, markdown_content: str, ir_page_url: str) -> Dict:
        """
        Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ Slack ã® Block Kit å½¢å¼ã«å¤‰æ›ã—ã¾ã™ã€‚

        Args:
            markdown_content (str): å¤‰æ›å¯¾è±¡ã®Markdownãƒ†ã‚­ã‚¹ãƒˆ
            ir_page_url (str): IRæƒ…å ±ãƒšãƒ¼ã‚¸ã¸ã®URL

        Returns:
            Dict: Block Kitå½¢å¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹é€ 
        """
        # ä¼šç¤¾åã‚’æŠ½å‡º
        company_name = self._extract_company_name(markdown_content)
        
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰²
        sections = self._split_sections(markdown_content)
        blocks = []

        # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆä¼šç¤¾åï¼‰
        blocks.append(self._create_header_block(company_name))

        # åŸºæœ¬æƒ…å ±ãƒ–ãƒ­ãƒƒã‚¯
        if sections['header']:
            blocks.append(self._create_section_block(
                self._format_summary(sections['header'])
            ))

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åŒºåˆ‡ã‚Š
        blocks.append({"type": "divider"})

        # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ–ãƒ­ãƒƒã‚¯
        for section in self._format_sections(sections['content']):
            blocks.append(self._create_section_block(
                f"*{section['title']}*\n{section['value']}"
            ))

        # ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±ã¨ãƒœã‚¿ãƒ³
        blocks.extend(self._create_footer_blocks(ir_page_url))

        return {"blocks": blocks}

    def _extract_company_name(self, markdown_content: str) -> str:
        """
        Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ä¼šç¤¾åã‚’æŠ½å‡ºã—ã¾ã™ã€‚
        å‰æ ªå¼ä¼šç¤¾ã¨å¾Œæ ªå¼ä¼šç¤¾ã®ä¸¡æ–¹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œã—ã¾ã™ã€‚

        Args:
            markdown_content (str): è§£æå¯¾è±¡ã®Markdownãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            str: æŠ½å‡ºã•ã‚ŒãŸä¼šç¤¾åã€è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯"ä¸æ˜ãªä¼šç¤¾å"
        """
        try:
            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ä¼šç¤¾åæ¬„ã§ã®æ¤œç´¢
            patterns = [
                r'ä¼šç¤¾å:\s*\*\*(æ ªå¼ä¼šç¤¾[^*]+)\*\*',  # å‰æ ªå¼ä¼šç¤¾ãƒ‘ã‚¿ãƒ¼ãƒ³
                r'ä¼šç¤¾å:\s*\*\*([^æ ª]+æ ªå¼ä¼šç¤¾)\*\*',  # å¾Œæ ªå¼ä¼šç¤¾ãƒ‘ã‚¿ãƒ¼ãƒ³
                r'æ±ºç®—çŸ­ä¿¡ã®è¦ç´„\s*\(\*\*(æ ªå¼ä¼šç¤¾[^*]+)\*\*\)',  # ã‚¿ã‚¤ãƒˆãƒ«ã§ã®å‰æ ªå¼ä¼šç¤¾
                r'æ±ºç®—çŸ­ä¿¡ã®è¦ç´„\s*\(\*\*([^æ ª]+æ ªå¼ä¼šç¤¾)\*\*\)'  # ã‚¿ã‚¤ãƒˆãƒ«ã§ã®å¾Œæ ªå¼ä¼šç¤¾
            ]
            
            for pattern in patterns:
                match = re.search(pattern, markdown_content)
                if match:
                    return match.group(1)
            
            return "ä¸æ˜ãªä¼šç¤¾å"
            
        except Exception as e:
            logger.error(f"ä¼šç¤¾åã®æŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return "ä¸æ˜ãªä¼šç¤¾å"

    def _create_header_block(self, company_name: str) -> Dict:
        """ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ–ãƒ­ãƒƒã‚¯ã‚’ä½œæˆã—ã¾ã™"""
        return {
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": f"{company_name}ã®æ±ºç®—æƒ…å ±",
                "emoji": True
            }
        }

    def _create_section_block(self, text: str) -> Dict:
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ–ãƒ­ãƒƒã‚¯ã‚’ä½œæˆã—ã¾ã™"""
        return {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": text
            }
        }

    def _create_footer_blocks(self, ir_page_url: str) -> List[Dict]:
        """ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±ã¨ãƒœã‚¿ãƒ³ãƒ–ãƒ­ãƒƒã‚¯ã‚’ä½œæˆã—ã¾ã™"""
        return [
            {"type": "divider"},
            {
                "type": "context",
                "elements": [{
                    "type": "mrkdwn",
                    "text": "ğŸ“Š é‡‘èåº EDINET / GPT4oã‚’ä½¿ç”¨ã—ã¦è¦ç´„ã—ã¦ã„ã¾ã™"
                }]
            },
            {
                "type": "actions",
                "elements": [{
                    "type": "button",
                    "text": {
                        "type": "plain_text",
                        "text": "ğŸ“‘ é–¢é€£IRæƒ…å ±ã‚’ã‚‚ã£ã¨è¦‹ã‚‹",
                        "emoji": True
                    },
                    "style": "primary",
                    "url": ir_page_url,
                    "action_id": "view_ir_info"
                }]
            }
        ]

    def _format_sections(self, content_sections: List[str]) -> List[Dict]:
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å†…å®¹ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã¾ã™"""
        fields = []
        for section in content_sections:
            matches = re.match(r'(\d+\.\s*)(.*)', section)
            if matches:
                title = matches.group(2).strip()
                content = '\n'.join(section.split('\n')[1:])
                fields.append({
                    "title": f"{self._get_section_icon(title)} {title}",
                    "value": self._format_content_text(content),
                    "short": False
                })
        return fields

    def _format_content_text(self, content: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ•´å½¢ã—ã¾ã™"""
        lines = []
        for line in content.split('\n'):
            line = line.strip()
            if line:
                if line.startswith('âœ¦ '):
                    lines.append(line)
                elif line.startswith('- '):
                    lines.append(f"âœ¦ {line[2:]}")
                else:
                    lines.append(line)
        return '\n'.join(lines)

    def _format_summary(self, header: str) -> str:
        """ã‚µãƒãƒªãƒ¼éƒ¨åˆ†ã‚’æ•´å½¢ã—ã¾ã™"""
        return '\n'.join(
            line.strip() for line in header.split('\n')[1:]
            if line.strip()
        )

    def _get_section_icon(self, title: str) -> str:
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«å¯¾å¿œã™ã‚‹ã‚¢ã‚¤ã‚³ãƒ³ã‚’å–å¾—ã—ã¾ã™"""
        icons = {
            'ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæˆé•·': 'ğŸ“Š',
            'æ–°ã—ã„ãƒˆãƒ”ãƒƒã‚¯': 'ğŸ†•',
            'æç›Šè¨ˆç®—æ›¸': 'ğŸ’¹',
            'å¸‚å ´ã‚„ç«¶äº‰ç’°å¢ƒ': 'ğŸ¢'
        }
        return icons.get(next((k for k in icons.keys() if k in title), ''), 'ğŸ“Œ')

    def _split_sections(self, content: str) -> Dict[str, any]:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰²ã—ã¾ã™"""
        parts = content.split('\n1.')
        header = parts[0].strip()
        content_sections = []

        if len(parts) > 1:
            remaining = '1.' + parts[1]
            current_section = []
            for line in remaining.split('\n'):
                if re.match(r'^\d+\.', line):
                    if current_section:
                        content_sections.append('\n'.join(current_section))
                    current_section = [line]
                else:
                    current_section.append(line)

            if current_section:
                content_sections.append('\n'.join(current_section))

        return {
            'header': header,
            'content': content_sections
        }

class SlackNotifier:
    """
    Slacké€šçŸ¥ã‚’å‡¦ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    ç’°å¢ƒè¨­å®šã®ç®¡ç†ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é€ä¿¡ã‚’æ‹…å½“ã—ã¾ã™ã€‚
    """
    def __init__(self, env_path: str = "config/secrets.env"):
        # ç’°å¢ƒå¤‰æ•°ã®è¨­å®šã‚’èª­ã¿è¾¼ã¿
        self._load_environment(env_path)
        
        # Slackã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ã‚’åˆæœŸåŒ–
        self.client = WebClient(token=self.slack_token)
        self.formatter = MarkdownSlackFormatter()
        logger.info("Slacké€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")

    def _load_environment(self, env_path: str):
        """ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™"""
        dotenv_path = Path(env_path)
        if not dotenv_path.exists():
            raise FileNotFoundError(f".env ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {env_path}")
        
        load_dotenv(dotenv_path)
        
        self.slack_token = os.getenv("SLACK_BOT_TOKEN")
        if not self.slack_token:
            raise ValueError("SLACK_BOT_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

        logger.info("ç’°å¢ƒè¨­å®šã®ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")

    def send_formatted_markdown(self, channel: str, markdown_content: str, ir_page_url: str):
        """
        ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸMarkdownã‚’Slackã«é€ä¿¡ã—ã¾ã™ã€‚
        ãƒœãƒƒãƒˆã®è¡¨ç¤ºåã¨ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ã¦é€ä¿¡ã‚’è¡Œã„ã¾ã™ã€‚

        Args:
            channel (str): é€ä¿¡å…ˆã®Slackãƒãƒ£ãƒ³ãƒãƒ«ID
            markdown_content (str): é€ä¿¡ã™ã‚‹Markdownå½¢å¼ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            ir_page_url (str): IRæƒ…å ±ãƒšãƒ¼ã‚¸ã®URL
        """
        try:
            formatted_content = self.formatter.format_content(
                markdown_content, ir_page_url
            )
            
            # åŸºæœ¬ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã«ãƒœãƒƒãƒˆã®è¡¨ç¤ºè¨­å®šã‚’è¿½åŠ 
            message_params = {
                **formatted_content,  # æ—¢å­˜ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
                "channel": channel,
                "username": "æ±ºç®—é€šçŸ¥bot",  # ãƒœãƒƒãƒˆã®è¡¨ç¤ºå
                "icon_emoji": ":chart_with_upwards_trend:",  # ğŸ“ˆ ã‚°ãƒ©ãƒ•ä¸Šæ˜‡ã®çµµæ–‡å­—
                # ã¾ãŸã¯ç”»åƒURLã‚’ä½¿ç”¨ã™ã‚‹å ´åˆï¼š
                # "icon_url": "https://example.com/path/to/bot-icon.png"
            }
            
            response = self.client.chat_postMessage(**message_params)
            logger.info(f"Slacké€šçŸ¥ã‚’é€ä¿¡ã—ã¾ã—ãŸ: {response['ts']}")
                
        except SlackApiError as e:
            logger.error(f"Slack API ã‚¨ãƒ©ãƒ¼: {e.response['error']}")
            raise
        except Exception as e:
            logger.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            raise

================================================================================
File: src\modules\spreadsheet_to_edinet.py
================================================================================

# spreadsheet_to_edinet.py

from datetime import datetime
from utils.environment import EnvironmentUtils as env
from utils.spreadsheet import SpreadsheetService
from modules.edinet.operations import EDINETOperations
from modules.pdfSummary.process_drive_file import process_drive_file
from utils.drive_handler import DriveHandler
from utils.date_utils import parse_date_string
from modules.slack.slack_notify import SlackNotifier

from utils.logging_config import get_logger

# åå‰ä»˜ããƒ­ã‚¬ãƒ¼ã‚’å–å¾—
logger = get_logger(__name__)

def log_download_to_sheet(spreadsheet_service, spreadsheet_id, log_sheet_name, log_data):
    """
    ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°ã‚·ãƒ¼ãƒˆã«è¨˜éŒ²ã™ã‚‹ã€‚
    ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å‹•çš„ã«å–å¾—ã—ã€åˆ—ã‚’ç‰¹å®šã—ã¦æ“ä½œã™ã‚‹ã€‚
    """
    try:
        sheet_data = spreadsheet_service.get_sheet_data(spreadsheet_id, log_sheet_name)

        if not sheet_data:
            logger.info(f"Log sheet '{log_sheet_name}' is empty. Initializing headers.")
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½¿ç”¨ã—ã¦åˆæœŸåŒ–
            default_headers = [
                'Release_Date',
                'EDINET_code',
                'stock_code',
                'corp_name',
                'doc_type',
                'drive_raw_data_file_name',
                'drive_raw_data_file_url',
                'drive_summary_file_urls',  # æ–°ã—ã„ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
                'timestamp'
            ]
            spreadsheet_service.update_sheet_data(
                spreadsheet_id, log_sheet_name, [default_headers]
            )
            sheet_data = [default_headers]

        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’å–å¾—
        headers = sheet_data[0]
        logger.info(f"Retrieved headers: {headers}")

        # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’è¿½åŠ 
        logger.info(f"Appending log data to sheet '{log_sheet_name}'.")
        spreadsheet_service.append_sheet_data(
            spreadsheet_id, log_sheet_name, log_data
        )
        logger.info("Log data appended successfully.")
    except Exception as e:
        logger.error(f"Failed to append log data to sheet '{log_sheet_name}': {e}")
        raise

def process_spreadsheet_data(config):
    """
    ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åŸºã« EDINET API ã‚’å‘¼ã³å‡ºã—ã€çµæœã‚’ Google Drive ã«ç›´æ¥ä¿å­˜ã€‚
    çµæœã‚’ log ã‚·ãƒ¼ãƒˆã«è¨˜éŒ²ã—ã€è¦ç´„ã‚’ Slack ã«é€šçŸ¥ã€‚
    """
    try:
        # ç’°å¢ƒå¤‰æ•°ã¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
        env.load_env()

        # ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        spreadsheet_service = SpreadsheetService()

        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã¨ãƒ­ã‚°ã‚·ãƒ¼ãƒˆåã‚’å–å¾—
        spreadsheet_id = spreadsheet_service.get_spreadsheet_id("SPREADSHEET", "ss_id_list")
        log_sheet_name = "log"

        # æ—¥ä»˜ç¯„å›²ã‚’å–å¾—
        try:
            start_date = parse_date_string(env.get_config_value("DATE_RANGE", "start_date"))
            end_date = parse_date_string(env.get_config_value("DATE_RANGE", "end_date"))
            logger.info(f"Using date range from settings: {start_date} to {end_date}")
        except ValueError as e:
            logger.error(f"Invalid date range configuration: {e}")
            raise

        # SlackNotifier ã®åˆæœŸåŒ–
        slack_notifier = SlackNotifier(env_path="config/secrets.env")
        # Slack ãƒãƒ£ãƒ³ãƒãƒ«åã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—
        slack_channel = env.get_config_value("SLACK", "channel_id")

        # list ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        list_data = spreadsheet_service.get_sheet_data(spreadsheet_id, "list")
        if not list_data:
            logger.error("No data found in the 'list' sheet.")
            return

        headers = list_data[0]
        data_rows = list_data[1:]
        if "EDINET_code" not in headers or "ir_page_url" not in headers or "check" not in headers:
            logger.error("'EDINET_code', 'ir_page_url', or 'check' column not found in the 'list' sheet.")
            return

        # å¿…è¦ãªåˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
        edinet_code_index = headers.index("EDINET_code")
        ir_page_url_index = headers.index("ir_page_url")
        check_index = headers.index("check")

        edinet_operations = EDINETOperations()

        # DriveHandler ã®åˆæœŸåŒ–
        service_account_file = env.get_service_account_file()
        drive_handler = DriveHandler(str(service_account_file))

        for row_index, row in enumerate(data_rows, start=2):
            # `check`åˆ—ãŒTRUEã§ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            check_value = row[check_index] if check_index < len(row) else "FALSE"
            if check_value.upper() != "TRUE":
                logger.info(f"Skipping row {row_index}: check value is not TRUE.")
                continue

            # å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            edinet_code = row[edinet_code_index]
            stock_code = row[headers.index("stock_code")] if "stock_code" in headers else ""
            corp_name = row[headers.index("corp_name")] if "corp_name" in headers else ""
            ir_page_url = row[ir_page_url_index] if ir_page_url_index < len(row) else ""

            logger.info(f"Processing row {row_index}: EDINET_code = {edinet_code}")

            if not ir_page_url:
                logger.warning(f"No IR page URL found for EDINET_code {edinet_code}.")
                continue

            try:
                documents = edinet_operations.get_documents_for_date_range(
                    start_date, end_date, [edinet_code]
                )

                for document in documents:
                    doc_id = document.get("docID")
                    doc_type_code = document.get("docTypeCode")
                    release_date = document.get("submitDateTime").split(" ")[0]
                    doc_type_name = EDINETOperations.TARGET_DOC_TYPES.get(doc_type_code, "ä¸æ˜")

                    # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
                    file_name = f"{edinet_code}_{doc_id}_{release_date.replace('-', '')}.pdf"

                    # ãƒ•ã‚©ãƒ«ãƒ€ã®å–å¾—ã¾ãŸã¯ä½œæˆ
                    folder_id = drive_handler.get_or_create_folder(
                        folder_name=edinet_code,
                        parent_folder_id=env.get_config_value("DRIVE", "parent_folder_id")
                    )

                    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    doc_data = edinet_operations.fetch_document_data(doc_id, doc_type_code)

                    if doc_data:
                        # Google Drive ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                        file_id = drive_handler.upload_file(
                            file_name=file_name,
                            file_content=doc_data,
                            folder_id=folder_id
                        )

                        # PDFã‚’è¦ç´„ã—ã¦Google Driveã«ä¿å­˜
                        try:
                            summary_file_ids = process_drive_file(file_id, folder_id)
                            summary_urls = [
                                f"https://drive.google.com/file/d/{fid}/view" for fid in summary_file_ids
                            ]
                        except Exception as e:
                            logger.error(f"Failed to summarize PDF: {e}")
                            summary_file_ids = []
                            summary_urls = []

                        # ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆã¨è¨˜éŒ²
                        file_url = f"https://drive.google.com/file/d/{file_id}/view"
                        log_data = [
                            [
                                release_date,
                                edinet_code,
                                stock_code,
                                corp_name,
                                doc_type_name,
                                file_name,
                                file_url,
                                ", ".join(summary_urls),
                                datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            ]
                        ]
                        log_download_to_sheet(
                            spreadsheet_service, spreadsheet_id, log_sheet_name, log_data
                        )
                        logger.info(f"File uploaded to Drive with URL: {file_url}")

                        # Slacké€šçŸ¥ã®å‡¦ç†ã‚’è¿½åŠ 
                        if summary_file_ids:
                            for summary_file_id in summary_file_ids:
                                try:
                                    markdown_content = drive_handler.get_file_content(summary_file_id)
                                    slack_notifier.send_formatted_markdown(
                                        slack_channel, markdown_content, ir_page_url
                                    )
                                    logger.info(f"Slackã«è¦ç´„ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ« ID: {summary_file_id}")
                                except Exception as e:
                                    logger.error(f"Slacké€šçŸ¥ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆãƒ•ã‚¡ã‚¤ãƒ« ID: {summary_file_id}ï¼‰: {e}")
                        else:
                            logger.warning("è¦ç´„ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€Slacké€šçŸ¥ã¯è¡Œã„ã¾ã›ã‚“ã§ã—ãŸã€‚")

                    else:
                        logger.warning(f"Failed to fetch document data: ID={doc_id}")

            except Exception as e:
                logger.error(f"Error processing EDINET_code {edinet_code}: {e}")
    except Exception as e:
        logger.error(f"Failed to process spreadsheet data: {e}")
        raise

================================================================================
File: src\utils\__init__.py
================================================================================

 


================================================================================
File: src\utils\date_utils.py
================================================================================

from datetime import datetime, timedelta

def parse_date_string(date_str: str) -> datetime:
    """
    æ—¥ä»˜æ–‡å­—åˆ—ã‚’è§£æã—ã¦ datetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™ã€‚
    "yesterday" ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã¯å‰æ—¥ã®æ—¥ä»˜ã‚’è¿”ã™ã€‚
    """
    if date_str.lower() == "yesterday":
        return datetime.now() - timedelta(days=1)
    return datetime.strptime(date_str, "%Y-%m-%d")


================================================================================
File: src\utils\drive_handler.py
================================================================================

# src/utils/drive_handler.py

import io
from googleapiclient.discovery import build
from google.oauth2 import service_account
from googleapiclient.http import MediaIoBaseDownload, MediaIoBaseUpload
from pathlib import Path
from datetime import datetime

from utils.logging_config import get_logger

logger = get_logger(__name__)

class DriveHandler:
    def __init__(self, service_account_file: str):
        """
        Google Drive API ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚

        Args:
            service_account_file (str): ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ã‚­ãƒ¼ JSON ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€‚
        """
        self.service_account_file = service_account_file
        try:
            self.credentials = service_account.Credentials.from_service_account_file(
                self.service_account_file,
                scopes=["https://www.googleapis.com/auth/drive"]
            )
            self.service = build("drive", "v3", credentials=self.credentials)
            logger.info("Google Drive API ã‚µãƒ¼ãƒ“ã‚¹ãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸã€‚")
        except Exception as e:
            logger.error(f"Google Drive API ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            raise

    def get_file_content(self, file_id: str) -> str:
        """
        æŒ‡å®šã•ã‚ŒãŸGoogle Driveãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’å–å¾—ã—ã¾ã™ã€‚

        Args:
            file_id (str): Google Driveã®ãƒ•ã‚¡ã‚¤ãƒ«ID

        Returns:
            str: ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹
        """
        try:
            request = self.service.files().get_media(fileId=file_id)
            file_content = request.execute()
            content = file_content.decode("utf-8")  # Markdown ãƒ•ã‚¡ã‚¤ãƒ«ã¯é€šå¸¸ UTF-8 å½¢å¼
            logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’å–å¾—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ID: {file_id}")
            return content
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ID: {file_id}, ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def save_summary_to_drive(self, folder_id: str, summary: str, file_name: str) -> str:
        """
        è¦ç´„ã‚’ Google Drive ã«ä¿å­˜ã—ã¾ã™ã€‚ä¸€æ„ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä»˜ä¸ã—ã¾ã™ã€‚

        Args:
            folder_id (str): ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã®ID
            summary (str): ä¿å­˜ã™ã‚‹è¦ç´„å†…å®¹
            file_name (str): ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å

        Returns:
            str: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ID
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            unique_file_name = f"{Path(file_name).stem}_{timestamp}{Path(file_name).suffix}"
            logger.info(f"è¦ç´„ã‚’ Google Drive ã«ä¿å­˜ã—ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«å: {unique_file_name}")

            file_metadata = {
                "name": unique_file_name,
                "parents": [folder_id]
            }

            media = MediaIoBaseUpload(
                io.BytesIO(summary.encode("utf-8")),
                mimetype="text/markdown"
            )

            file = self.service.files().create(
                body=file_metadata,
                media_body=media,
                fields="id"
            ).execute()

            file_id = file.get("id")
            logger.info(f"è¦ç´„ã‚’ Google Drive ã«ä¿å­˜ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ« ID: {file_id}")
            return file_id
        except Exception as e:
            logger.error(f"è¦ç´„ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            raise

    def download_pdf_from_drive(self, file_id: str) -> str:
        """
        Google Drive ã‹ã‚‰PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

        Args:
            file_id (str): ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®Google Drive ID

        Returns:
            str: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹
        """
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            file_metadata = self.service.files().get(fileId=file_id).execute()
            file_name = file_metadata.get('name')

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ˆã®ãƒ‘ã‚¹ã‚’è¨­å®š
            download_dir = Path("downloads")
            download_dir.mkdir(exist_ok=True)
            local_path = download_dir / file_name

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            request = self.service.files().get_media(fileId=file_id)
            fh = io.BytesIO()
            downloader = MediaIoBaseDownload(fh, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()
                if status:
                    logger.debug(f"Download {int(status.progress() * 100)}%.")

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸå†…å®¹ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open(local_path, 'wb') as f:
                f.write(fh.getvalue())

            logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {local_path}")
            return str(local_path)
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            raise

    def get_or_create_folder(self, folder_name: str, parent_folder_id: str = None) -> str:
        """
        æŒ‡å®šã•ã‚ŒãŸåå‰ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’å–å¾—ã¾ãŸã¯ä½œæˆã—ã¾ã™ã€‚

        Args:
            folder_name (str): ãƒ•ã‚©ãƒ«ãƒ€åã€‚
            parent_folder_id (str, optional): è¦ªãƒ•ã‚©ãƒ«ãƒ€ã®IDã€‚

        Returns:
            str: ãƒ•ã‚©ãƒ«ãƒ€ã®IDã€‚
        """
        try:
            # ãƒ•ã‚©ãƒ«ãƒ€æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰
            query = f"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false"
            if parent_folder_id:
                query += f" and '{parent_folder_id}' in parents"

            # ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œç´¢
            results = self.service.files().list(
                q=query,
                spaces="drive",
                fields="files(id, name)",
                pageSize=1
            ).execute()
            files = results.get("files", [])

            if files:
                folder_id = files[0]["id"]
                logger.info(f"æ—¢å­˜ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ãƒ•ã‚©ãƒ«ãƒ€å: '{folder_name}', ãƒ•ã‚©ãƒ«ãƒ€ID: {folder_id}")
                return folder_id
            else:
                # ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
                file_metadata = {
                    "name": folder_name,
                    "mimeType": "application/vnd.google-apps.folder",
                    "parents": [parent_folder_id] if parent_folder_id else [],
                }
                folder = self.service.files().create(
                    body=file_metadata,
                    fields="id"
                ).execute()
                folder_id = folder.get("id")
                logger.info(f"æ–°è¦ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã—ãŸã€‚ãƒ•ã‚©ãƒ«ãƒ€å: '{folder_name}', ãƒ•ã‚©ãƒ«ãƒ€ID: {folder_id}")
                return folder_id
        except Exception as e:
            logger.error(f"ãƒ•ã‚©ãƒ«ãƒ€ã®å–å¾—ã¾ãŸã¯ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            raise

    def upload_file(self, file_name: str, file_content: bytes, folder_id: str, mime_type: str = "application/pdf") -> str:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Google Driveã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
        æ—¢å­˜ã®åŒåãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã€‚

        Args:
            file_name (str): ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åã€‚
            file_content (bytes): ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã€‚
            folder_id (str): ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…ˆã®ãƒ•ã‚©ãƒ«ãƒ€IDã€‚
            mime_type (str): ãƒ•ã‚¡ã‚¤ãƒ«ã®MIMEã‚¿ã‚¤ãƒ—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯PDFï¼‰ã€‚

        Returns:
            str: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®IDã€‚ã¾ãŸã¯æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®IDã€‚
        """
        try:
            # ãƒ•ã‚©ãƒ«ãƒ€å†…ã§åŒåãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            query = f"name='{file_name}' and '{folder_id}' in parents and trashed=false"
            results = self.service.files().list(
                q=query,
                spaces="drive",
                fields="files(id, name)",
                pageSize=1
            ).execute()
            existing_files = results.get("files", [])

            if existing_files:
                # åŒåãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                file_id = existing_files[0]["id"]
                logger.info(f"åŒåãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: '{file_name}' (ãƒ•ã‚©ãƒ«ãƒ€ID: {folder_id}, ãƒ•ã‚¡ã‚¤ãƒ«ID: {file_id})")
                return file_id

            # ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
            file_metadata = {
                "name": file_name,
                "parents": [folder_id],
            }

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            media = MediaIoBaseUpload(
                io.BytesIO(file_content),
                mimetype=mime_type
            )
            uploaded_file = self.service.files().create(
                body=file_metadata,
                media_body=media,
                fields="id"
            ).execute()
            file_id = uploaded_file.get("id")
            logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: '{file_name}' (ãƒ•ã‚©ãƒ«ãƒ€ID: {folder_id}, ãƒ•ã‚¡ã‚¤ãƒ«ID: {file_id})")
            return file_id
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            raise


================================================================================
File: src\utils\environment.py
================================================================================

#enviroment.py
import os
from pathlib import Path
from dotenv import load_dotenv
from typing import Optional, Any
import configparser

class EnvironmentUtils:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã§ä½¿ç”¨ã™ã‚‹ç’°å¢ƒé–¢é€£ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹"""

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    BASE_DIR = Path(__file__).resolve().parent.parent.parent

    @staticmethod
    def set_project_root(path: Path) -> None:
        """
        ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®šã—ã¾ã™ã€‚

        Args:
            path (Path): æ–°ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
        """
        EnvironmentUtils.BASE_DIR = path

    @staticmethod
    def get_project_root() -> Path:
        """
        ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—ã—ã¾ã™ã€‚

        Returns:
            Path: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        return EnvironmentUtils.BASE_DIR

    @staticmethod
    def load_env(env_file: Optional[Path] = None) -> None:
        """
        ç’°å¢ƒå¤‰æ•°ã‚’ .env ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

        Args:
            env_file (Optional[Path]): .env ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        env_file = env_file or (EnvironmentUtils.BASE_DIR / "config" / "secrets.env")

        if not env_file.exists():
            raise FileNotFoundError(f"{env_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ­£ã—ã„ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

        load_dotenv(env_file)

    @staticmethod
    def get_env_var(key: str, default: Optional[Any] = None) -> Any:
        """
        ç’°å¢ƒå¤‰æ•°ã‚’å–å¾—ã—ã¾ã™ã€‚

        Args:
            key (str): ç’°å¢ƒå¤‰æ•°ã®ã‚­ãƒ¼
            default (Optional[Any]): ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

        Returns:
            Any: ç’°å¢ƒå¤‰æ•°ã®å€¤ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        """
        return os.getenv(key, default)

    @staticmethod
    def get_config_file(file_name: str = "settings.ini") -> Path:
        """
        è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—ã—ã¾ã™ã€‚

        Args:
            file_name (str): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å

        Returns:
            Path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Raises:
            FileNotFoundError: æŒ‡å®šã•ã‚ŒãŸè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
        """
        config_path = EnvironmentUtils.BASE_DIR / "config" / file_name
        if not config_path.exists():
            raise FileNotFoundError(f"Configuration file not found: {config_path}")
        return config_path

    @staticmethod
    def get_config_value(section: str, key: str, default: Optional[Any] = None) -> Any:
        """
        è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æŒ‡å®šã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¨ã‚­ãƒ¼ã®å€¤ã‚’å–å¾—ã—ã¾ã™ã€‚

        Args:
            section (str): ã‚»ã‚¯ã‚·ãƒ§ãƒ³å
            key (str): ã‚­ãƒ¼å
            default (Optional[Any]): ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

        Returns:
            Any: è¨­å®šå€¤
        """
        config_path = EnvironmentUtils.get_config_file()
        config = configparser.ConfigParser()
        config.read(config_path, encoding='utf-8')  # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š

        if not config.has_section(section):
            return default
        if not config.has_option(section, key):
            return default

        value = config.get(section, key, fallback=default)

        # å‹å¤‰æ›
        if value.isdigit():
            return int(value)
        if value.replace('.', '', 1).isdigit():
            return float(value)
        if value.lower() in ['true', 'false']:
            return value.lower() == 'true'
        return value

    @staticmethod
    def resolve_path(path: str) -> Path:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã«åŸºã¥ã„ã¦çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›ã—ã¾ã™ã€‚

        Args:
            path (str): ç›¸å¯¾ãƒ‘ã‚¹ã¾ãŸã¯çµ¶å¯¾ãƒ‘ã‚¹

        Returns:
            Path: è§£æ±ºã•ã‚ŒãŸçµ¶å¯¾ãƒ‘ã‚¹
        """
        resolved_path = Path(path)
        if not resolved_path.is_absolute():
            resolved_path = EnvironmentUtils.get_project_root() / resolved_path

        if not resolved_path.exists():
            raise FileNotFoundError(f"Resolved path does not exist: {resolved_path}")

        return resolved_path

    @staticmethod
    def get_service_account_file() -> Path:
        """
        ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—ã—ã¾ã™ã€‚

        Returns:
            Path: ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®çµ¶å¯¾ãƒ‘ã‚¹

        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        """
        # ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—
        service_account_file = EnvironmentUtils.get_env_var(
            "SERVICE_ACCOUNT_FILE",
            default=EnvironmentUtils.get_config_value("GOOGLE", "service_account_file", default="config/service_account.json")
        )

        # ãƒ‘ã‚¹ã‚’è§£æ±º
        return EnvironmentUtils.resolve_path(service_account_file)

    @staticmethod
    def get_environment() -> str:
        """
        ç’°å¢ƒå¤‰æ•° APP_ENV ã‚’å–å¾—ã—ã¾ã™ã€‚
        ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¯ 'development' ã§ã™ã€‚

        Returns:
            str: ç¾åœ¨ã®ç’°å¢ƒï¼ˆä¾‹: 'development', 'production'ï¼‰
        """
        return EnvironmentUtils.get_env_var("APP_ENV", "development")

    @staticmethod
    def get_openai_api_key():
        """
        Get the OpenAI API key from the environment variables.
        """
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return api_key

    @staticmethod
    def get_openai_model():
        """
        Get the OpenAI model name from the environment variables.
        Defaults to 'gpt-4o' if not explicitly set.
        """
        return os.getenv("OPENAI_MODEL", "gpt-4o")

================================================================================
File: src\utils\logging_config.py
================================================================================

import logging
import logging.handlers
from datetime import datetime
from pathlib import Path
from icecream import ic
from typing import Optional

class LoggingConfig:
    _initialized = False

    def __init__(self, use_icecream: bool = False):
        """
        ãƒ­ã‚°è¨­å®šã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚

        Args:
            use_icecream (bool): IceCreamãƒ‡ãƒãƒƒã‚°ã‚’æœ‰åŠ¹åŒ–ã™ã‚‹ã‹
        """
        if LoggingConfig._initialized:
            return  # å†åˆæœŸåŒ–ã‚’é˜²æ­¢

        self.log_dir = Path("logs")
        self.log_level = logging.INFO
        self.log_format = "%(asctime)s - %(name)s - [%(levelname)s] - %(message)s"
        self.use_icecream = use_icecream

        self.setup_logging()
        self.initialize_icecream()

        LoggingConfig._initialized = True  # åˆæœŸåŒ–æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’è¨­å®š

    def setup_logging(self) -> None:
        """
        ãƒ­ã‚®ãƒ³ã‚°è¨­å®šã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚
        """
        if not self.log_dir.exists():
            self.log_dir.mkdir(parents=True, exist_ok=True)

        log_file = self.log_dir / f"app_{datetime.now().strftime('%Y%m%d')}.log"

        handlers = [
            logging.handlers.TimedRotatingFileHandler(
                log_file, when="midnight", interval=1, backupCount=30, encoding="utf-8"
            ),
            logging.StreamHandler(),
        ]

        logging.basicConfig(
            level=self.log_level,
            format=self.log_format,
            handlers=handlers,
        )

        logging.getLogger().info("Logging setup complete.")

    def initialize_icecream(self) -> None:
        """
        IceCreamã®ãƒ‡ãƒãƒƒã‚°è¨­å®šã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
        """
        if self.use_icecream:
            ic.configureOutput(includeContext=True)
            logging.getLogger().info("IceCream debugging enabled.")
        else:
            ic.disable()
            logging.getLogger().info("IceCream debugging disabled.")

def get_logger(name: Optional[str] = None, use_icecream: bool = False) -> logging.Logger:
    """
    åå‰ä»˜ããƒ­ã‚¬ãƒ¼ã‚’å–å¾—ã—ã¾ã™ã€‚

    Args:
        name (Optional[str]): ãƒ­ã‚¬ãƒ¼å
        use_icecream (bool): IceCreamãƒ‡ãƒãƒƒã‚°ã‚’æœ‰åŠ¹åŒ–ã™ã‚‹ã‹

    Returns:
        logging.Logger: åå‰ä»˜ããƒ­ã‚¬ãƒ¼
    """
    LoggingConfig(use_icecream=use_icecream)
    return logging.getLogger(name)


================================================================================
File: src\utils\spreadsheet.py
================================================================================

import os
from pathlib import Path
from configparser import ConfigParser
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build

from utils.environment import EnvironmentUtils as env
from utils.logging_config import get_logger

class SpreadsheetService:
    """ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ“ä½œã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        """
        åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰ã€‚
        ãƒ­ã‚°è¨­å®šã¨Google Sheets APIã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ã‚’è¡Œã„ã¾ã™ã€‚
        """
        self.logger = get_logger(__name__)
        self.logger.info("Initializing SpreadsheetService...")

        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        try:
            # ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—
            service_account_file = os.getenv("SERVICE_ACCOUNT_FILE", "config/service_account.json")
            
            # ãƒ‘ã‚¹ã‚’è§£æ±º
            service_account_path = self._resolve_path(service_account_file)

            # Google èªè¨¼æƒ…å ±ã‚’ãƒ­ãƒ¼ãƒ‰
            if not service_account_path.exists():
                raise FileNotFoundError(f"Service account file not found: {service_account_path}")

            self.credentials = Credentials.from_service_account_file(str(service_account_path))
            self.logger.info("Service account file successfully loaded.")
        except Exception as e:
            self.logger.error(f"Failed to load service account file: {e}")
            raise

        # Google Sheets API ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–
        try:
            self.service = build("sheets", "v4", credentials=self.credentials)
            self.logger.info("Google Sheets API service initialized successfully.")
        except Exception as e:
            self.logger.error(f"Failed to initialize Google Sheets API service: {e}")
            raise

        # ConfigParser ã§è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        try:
            config_path = env.get_config_file()
            self.logger.info(f"Loading configuration from: {config_path}")
            self.config = ConfigParser()

            if not config_path.exists():
                raise FileNotFoundError(f"Configuration file not found: {config_path}")

            self.config.read(config_path, encoding='utf-8')  # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
        except Exception as e:
            self.logger.error(f"Error loading configuration: {e}")
            raise

    def _resolve_path(self, path: str) -> Path:
        """
        ä¸ãˆã‚‰ã‚ŒãŸãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«è§£æ±ºã—ã¾ã™ã€‚

        :param path: è§£æ±ºã™ã‚‹ãƒ‘ã‚¹
        :return: çµ¶å¯¾ãƒ‘ã‚¹
        """
        resolved_path = Path(path)
        if not resolved_path.is_absolute():
            resolved_path = env.get_project_root() / resolved_path

        self.logger.debug(f"Resolved path: {resolved_path}")
        return resolved_path

    def get_sheet_data(self, spreadsheet_id: str, sheet_name: str):
        """
        æŒ‡å®šã•ã‚ŒãŸã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã€‚

        Args:
            spreadsheet_id (str): ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆID
            sheet_name (str): ã‚·ãƒ¼ãƒˆå

        Returns:
            List[List[str]]: ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿
        """
        self.logger.info(f"Fetching data from Spreadsheet ID: {spreadsheet_id}, Sheet Name: {sheet_name}")
        try:
            sheet = self.service.spreadsheets()
            result = sheet.values().get(spreadsheetId=spreadsheet_id, range=sheet_name).execute()
            data = result.get("values", [])
            self.logger.debug(f"Data fetched: {data}")
            return data
        except Exception as e:
            self.logger.error(f"Error fetching data for Sheet '{sheet_name}': {e}")
            raise

    def get_spreadsheet_id(self, section: str, option: str) -> str:
        """
        ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã‚’å–å¾—ã—ã¾ã™ã€‚

        Args:
            section (str): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³å
            option (str): è¨­å®šé …ç›®å

        Returns:
            str: ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆID
        """
        self.logger.info(f"Fetching Spreadsheet ID from section: {section}, option: {option}")
        try:
            if not self.config.has_section(section):
                raise ValueError(f"Section '{section}' not found in the configuration.")
            if not self.config.has_option(section, option):
                raise ValueError(f"Option '{option}' not found in section '{section}'.")
            spreadsheet_id = self.config.get(section, option)
            self.logger.debug(f"Spreadsheet ID retrieved: {spreadsheet_id}")
            return spreadsheet_id
        except Exception as e:
            self.logger.error(f"Error retrieving Spreadsheet ID: {e}")
            raise

    def append_sheet_data(self, spreadsheet_id: str, sheet_name: str, rows: list):
        """
        æŒ‡å®šã•ã‚ŒãŸã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ã‚·ãƒ¼ãƒˆã«è¡Œãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¾ã™ã€‚

        Args:
            spreadsheet_id (str): ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆID
            sheet_name (str): ã‚·ãƒ¼ãƒˆå
            rows (list): è¿½åŠ ã™ã‚‹è¡Œãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ

        Returns:
            dict: APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        """
        self.logger.info(f"Appending data to Spreadsheet ID: {spreadsheet_id}, Sheet Name: {sheet_name}")
        try:
            range_ = f"{sheet_name}!A1"
            body = {"values": rows}

            response = self.service.spreadsheets().values().append(
                spreadsheetId=spreadsheet_id,
                range=range_,
                valueInputOption="RAW",
                insertDataOption="INSERT_ROWS",
                body=body
            ).execute()

            self.logger.debug(f"Data appended successfully to Sheet: {sheet_name}, Response: {response}")
            return response
        except Exception as e:
            self.logger.error(f"Error appending data to sheet '{sheet_name}': {e}")
            raise


================================================================================
File: tests\__init__.py
================================================================================

 


================================================================================
File: tests\test_drive_file.py
================================================================================

#test_drive_file.py
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨ˆç®—ã—ã¦Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).resolve().parent.parent
sys.path.append(str(project_root))
sys.path.append(str(project_root / "src"))  # srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚è¿½åŠ 

# modulesé…ä¸‹ã®pdf_mainã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from modules.pdfSummary.pdf_main import test_process_drive_file

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Test processing a Google Drive PDF file by its file ID.")
    parser.add_argument("file_id", help="The Google Drive file ID of the PDF to process.")
    parser.add_argument("drive_folder_id", help="The Google Drive folder ID to save the summary.")
    args = parser.parse_args()

    try:
        test_process_drive_file(args.file_id, args.drive_folder_id)
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

================================================================================
File: tests\test_log.py
================================================================================

import logging
from logging.handlers import TimedRotatingFileHandler
from pathlib import Path
from datetime import datetime

def test_logging():
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    log_file = log_dir / f"app_{datetime.now().strftime('%Y%m%d')}.log"

    logger = logging.getLogger("test_logger")
    logger.setLevel(logging.DEBUG)

    handler = TimedRotatingFileHandler(
        log_file,
        when='midnight',
        interval=1,
        backupCount=30,
        encoding='utf-8'
    )

    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    logger.info("This is a test log message.")

if __name__ == "__main__":
    test_logging()


================================================================================
File: tests\test_slack_notify.py
================================================================================

import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨ˆç®—ã—ã¦ Python ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).resolve().parent.parent
sys.path.append(str(project_root))
sys.path.append(str(project_root / "src"))  # src ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚è¿½åŠ 

from modules.slack.slack_notify import test_slack_notification_with_file

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Test sending a Slack notification with a file link.")
    parser.add_argument("slack_channel", help="The Slack channel to send the notification.")
    parser.add_argument("message", help="The message to send to the Slack channel.")
    parser.add_argument("file_id", help="The Google Drive file ID to share.")
    parser.add_argument("--env_path", default="config/secrets.env", help="Path to the .env file (default: config/secrets.env).")
    args = parser.parse_args()

    try:
        test_slack_notification_with_file(args.slack_channel, args.message, args.file_id, args.env_path)
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


================================================================================
File: tests\test_slack_notify_with_file.py
================================================================================

import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨ˆç®—ã—ã¦ Python ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).resolve().parent.parent
sys.path.append(str(project_root))
sys.path.append(str(project_root / "src"))  # src ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚è¿½åŠ 

from modules.slack.slack_notify import SlackNotifier

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Slacké€šçŸ¥ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚")
    parser.add_argument("slack_channel", help="Slackã®é€šçŸ¥å…ˆãƒãƒ£ãƒ³ãƒãƒ«åã¾ãŸã¯IDã€‚")
    parser.add_argument("file_id", help="Google Driveä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«IDã€‚")
    args = parser.parse_args()

    try:
        notifier = SlackNotifier(env_path="config/secrets.env")
        notifier.notify_with_file_content(args.slack_channel, args.file_id)
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


================================================================================
File: tests\test_slack_notify_with_markdown.py
================================================================================

#test_slack_notify_with_markdown.py
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨ˆç®—ã—ã¦ Python ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).resolve().parent.parent
sys.path.append(str(project_root))
sys.path.append(str(project_root / "src"))  # src ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚è¿½åŠ 

from modules.slack.slack_notify import SlackNotifier
from modules.slack.drive_handler import DriveHandler
from utils.logging_config import get_logger


logger = get_logger(__name__)

def test_slack_notification_with_markdown(slack_channel: str, file_id: str, env_path: str = "config/secrets.env"):
    try:
        notifier = SlackNotifier(env_path=env_path)
        drive_handler = DriveHandler(notifier.service_account_file)
        content = drive_handler.get_file_content(file_id)
        notifier.send_formatted_markdown(slack_channel, content)
    except Exception as e:
        logger.error(f"Slacké€šçŸ¥ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        raise

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("Usage: python test_slack_notify_with_markdown.py [channel] [file_id]")
        sys.exit(1)
    
    test_slack_notification_with_markdown(sys.argv[1], sys.argv[2])

================================================================================
File: tests\test_spreadsheet.py
================================================================================

import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).resolve().parent.parent  # ir_news_release ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
sys.path.append(str(project_root / "src"))

from utils.spreadsheet import SpreadsheetService
from icecream import ic

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
CONFIG_PATH = Path("config/settings.ini")

def test_list_sheet_headers():
    """list ã‚·ãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€è¡Œã‚’å–å¾—ã—ã¦ç¢ºèª"""
    service = SpreadsheetService(CONFIG_PATH)
    data = service.get_sheet_data("list")

    if data:
        ic(data[0])  # æœ€åˆã®è¡Œã‚’å‡ºåŠ›ï¼ˆãƒ˜ãƒƒãƒ€è¡Œï¼‰
    else:
        print("No data found in 'list' sheet.")

if __name__ == "__main__":
    test_list_sheet_headers()


================================================================================
File: tests\test_template.py
================================================================================

import sys
from pathlib import Path
import os
from icecream import ic
from configparser import ConfigParser

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨ˆç®—ã—ã€`src` ã‚’ `sys.path` ã«è¿½åŠ 
project_root = Path(__file__).resolve().parent.parent  # ir_news_release ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
src_path = project_root / "src"  # src ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
sys.path.insert(0, str(src_path))  # sys.path ã®å…ˆé ­ã«è¿½åŠ 

from utils.logging_config import get_logger

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
CONFIG_PATH = project_root / "config/settings.ini"
ENV_PATH = project_root / "config/secrets.env"

def load_environment_variables(env_path):
    """
    secrets.env ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
    """
    if not env_path.exists():
        raise FileNotFoundError(f"Environment file not found: {env_path}")
    
    with open(env_path) as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith("#"):  # ç©ºè¡Œã‚„ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—
                continue
            key, value = line.split("=", 1)
            os.environ[key] = value
    ic(f"Environment variables loaded from {env_path}")

def sample_function():
    """
    ã‚µãƒ³ãƒ—ãƒ«é–¢æ•°ï¼šHello TOMONOKAI ã‚’å‡ºåŠ›ã—ã€ãƒ­ã‚°ã¨ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚’è¡Œã†
    """
    # ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–
    logger = get_logger()
    logger.info("Starting sample function")

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    config = ConfigParser()
    if CONFIG_PATH.exists():
        config.read(CONFIG_PATH)
        ic(f"Configuration loaded: {CONFIG_PATH}")
    else:
        logger.error(f"Configuration file not found: {CONFIG_PATH}")

    # secrets.env ã®èª­ã¿è¾¼ã¿
    try:
        load_environment_variables(ENV_PATH)
        logger.info(f"Environment variables loaded successfully from {ENV_PATH}")
    except FileNotFoundError as e:
        logger.error(str(e))
        return

    # ã‚µãƒ³ãƒ—ãƒ«å‡ºåŠ›
    api_key = os.getenv("EDINET_API_KEY", "æœªè¨­å®š")
    logger.info(f"EDINET_API_KEY: {api_key}")
    ic(f"EDINET_API_KEY: {api_key}")

    print("Hello TOMONOKAI")
    logger.info("Sample function completed successfully.")

if __name__ == "__main__":
    sample_function()

